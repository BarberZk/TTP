{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-09T18:04:08.277026Z",
     "start_time": "2025-09-09T18:04:04.537514Z"
    }
   },
   "source": [
    "import torch\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "#MERGED_MODEL_PATH = \"./qwen3-4b-sft-merged-final\"\n",
    "MERGED_MODEL_PATH = \"./Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "TEST_DATASET_PATH = \"./data/input/sft_dataset_4000_test.json\"\n",
    "\n",
    "#RESULTS_OUTPUT_PATH =  \"./evaluation_results.json\"\n",
    "RESULTS_OUTPUT_PATH =  \"./evaluation_results_1.json\"\n",
    "\n",
    "print(\"✅ 配置加载完成\")\n",
    "print(f\"模型路径: {MERGED_MODEL_PATH}\")\n",
    "print(f\"测试集路径: {TEST_DATASET_PATH}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 配置加载完成\n",
      "模型路径: ./Qwen3-4B-Instruct-2507\n",
      "测试集路径: ./data/input/sft_dataset_4000_test.json\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:04:08.283411Z",
     "start_time": "2025-09-09T18:04:08.280035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_prompt(instruction, input_text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in cybersecurity and the MITRE ATT&CK framework.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\\n\\n{input_text}\"}\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def extract_technique_id(text):\n",
    "    #正则表达式匹配T10043 等等\n",
    "    match = re.search(r'T\\d{4}(\\.\\d{3})?', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None\n"
   ],
   "id": "3e12dd6391ed82c7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 加载模型",
   "id": "78de5f2fcd20c0ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:04:18.038321Z",
     "start_time": "2025-09-09T18:04:08.499079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "compute_dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_properties(0).major >= 8 else torch.float16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MERGED_MODEL_PATH, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MERGED_MODEL_PATH,\n",
    "    dtype=compute_dtype,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval() # 设置为评估模式\n"
   ],
   "id": "e9849875ac3e61f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f79b4466659a401f968301c26b2930d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:04:19.056044Z",
     "start_time": "2025-09-09T18:04:18.102806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = load_dataset(\"json\", data_files=str(TEST_DATASET_PATH), split=\"train\")\n",
    "print(f\"✅ 测试集加载成功，共 {len(test_dataset)} 条数据。\")"
   ],
   "id": "768a18028850ee57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 测试集加载成功，共 1000 条数据。\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 评估函数\n",
    "目前方法仅提取方法编号进行字符串匹配比较。"
   ],
   "id": "cfedecd3e9fa116f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:27:10.244516Z",
     "start_time": "2025-09-09T18:04:19.060055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correct_predictions = 0\n",
    "total_samples = len(test_dataset)\n",
    "evaluation_results = []\n",
    "\n",
    "\n",
    "\n",
    "for sample in tqdm(test_dataset, desc=\"评估进度\"):\n",
    "    instruction = sample[\"instruction\"]\n",
    "    input_text = sample[\"input\"]\n",
    "    ground_truth = sample[\"output\"]\n",
    "\n",
    "    # 1. 创建提示\n",
    "    messages = create_prompt(instruction, input_text)\n",
    "    prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    # 2. 模型推理\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    # 3. 解码并清理输出\n",
    "    response_ids = outputs[0][inputs.input_ids.shape[1]:]\n",
    "    prediction = tokenizer.decode(response_ids, skip_special_tokens=True)\n",
    "\n",
    "    # 4. 提取 T-ID\n",
    "    ground_truth_id = extract_technique_id(ground_truth)\n",
    "    prediction_id = extract_technique_id(prediction)\n",
    "\n",
    "    # 5. 比较结果\n",
    "    is_correct = (ground_truth_id is not None and ground_truth_id == prediction_id)\n",
    "    if is_correct:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    # 6. 记录详细结果\n",
    "    evaluation_results.append({\n",
    "        \"input\": input_text,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"prediction\": prediction,\n",
    "        \"ground_truth_id\": ground_truth_id,\n",
    "        \"prediction_id\": prediction_id,\n",
    "        \"is_correct\": is_correct\n",
    "    })"
   ],
   "id": "faaec43615a40e77",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "评估进度:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb2cd21e9a9d4d95b34dfd8b87dfa79a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 保存结果",
   "id": "730d196265dc6f5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T18:27:10.328868Z",
     "start_time": "2025-09-09T18:27:10.317014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy = (correct_predictions / total_samples) * 100 if total_samples > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"      模型评估结果\")\n",
    "print(\"=\"*30)\n",
    "print(f\"总测试样本数: {total_samples}\")\n",
    "print(f\"正确预测数: {correct_predictions}\")\n",
    "print(f\"准确率 (Accuracy): {accuracy:.2f}%\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "# --- 保存详细结果到文件 ---\n",
    "print(f\"\\n正在将详细评估结果保存到 '{RESULTS_OUTPUT_PATH}'...\")\n",
    "with open(RESULTS_OUTPUT_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump(evaluation_results, f, indent=4, ensure_ascii=False)\n"
   ],
   "id": "f23a5114acd08e4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "      模型评估结果\n",
      "==============================\n",
      "总测试样本数: 1000\n",
      "正确预测数: 4\n",
      "准确率 (Accuracy): 0.40%\n",
      "==============================\n",
      "\n",
      "正在将详细评估结果保存到 './evaluation_results_1.json'...\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
