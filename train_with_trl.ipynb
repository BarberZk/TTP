{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-08T14:35:00.595397Z",
     "start_time": "2025-09-08T14:34:56.607780Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTConfig, SFTTrainer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T14:35:00.600594Z",
     "start_time": "2025-09-08T14:35:00.598405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"./Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "dataset_path = \"./data/input/sft_dataset_4000.json\"\n",
    "\n",
    "# è®­ç»ƒå LoRA é€‚é…å™¨çš„ä¸´æ—¶ä¿å­˜è·¯å¾„\n",
    "lora_adapter_path = \"./qwen3-4b-sft-lora-adapter-8bit\"\n",
    "# æœ€ç»ˆåˆå¹¶åå®Œæ•´æ¨¡å‹çš„ä¿å­˜è·¯å¾„\n",
    "merged_model_path = \"./qwen3-4b-sft-merged-final\""
   ],
   "id": "7e2a575fc72a509b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T14:35:06.796256Z",
     "start_time": "2025-09-08T14:35:00.697464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "compute_dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_properties(0).major >= 8 else torch.float16\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=compute_dtype,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "id": "7d28e2ade3b5948b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f86fc06582c4fdeb28ddc3e437fa4dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T14:35:06.825612Z",
     "start_time": "2025-09-08T14:35:06.823340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset = load_dataset(\"json\", data_files=dataset_path, split=\"train\")\n",
    "#\n",
    "# def format_prompt(example):\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in cybersecurity and the MITRE ATT&CK framework.\"},\n",
    "#         {\"role\": \"user\", \"content\": f\"{example['instruction']}\\n\\n{example['input']}\"},\n",
    "#         {\"role\": \"assistant\", \"content\": example['output']}\n",
    "#     ]\n",
    "#     prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "#     return {\"text\": prompt}\n",
    "#\n",
    "# formatted_dataset = dataset.map(format_prompt)\n",
    "#\n",
    "# print(\"æ•°æ®é›†æ ¼å¼åŒ–å®Œæˆã€‚ç¤ºä¾‹å¦‚ä¸‹ï¼š\")\n",
    "# print(formatted_dataset[0]['text'])"
   ],
   "id": "1d596a7a956d214c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T14:35:07.804601Z",
     "start_time": "2025-09-08T14:35:06.854206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "dataset = load_dataset(\"json\", data_files=str(dataset_path), split=\"train\")\n",
    "\n",
    "def format_prompt_function(example):\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in cybersecurity and the MITRE ATT&CK framework.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{example['instruction']}\\n\\n{example['input']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": example['output']}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "formatted_dataset = dataset.map(format_prompt_function, remove_columns=list(dataset.features))\n",
    "\n",
    "print(\"\\nç¤ºä¾‹å¦‚ä¸‹ï¼š\")\n",
    "print(formatted_dataset[0]['messages'])"
   ],
   "id": "4949a277270a90be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ç¤ºä¾‹å¦‚ä¸‹ï¼š\n",
      "[{'content': 'You are a helpful assistant specialized in cybersecurity and the MITRE ATT&CK framework.', 'role': 'system'}, {'content': 'Find the techniques and ID from MITRE ATT&CK framework.\\n\\nTrickBot has used macros in Excel documents to download and deploy the malware on the userâ€™s machine.', 'role': 'user'}, {'content': 'T1059: Command and Scripting Interpreter', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T14:35:09.295952Z",
     "start_time": "2025-09-08T14:35:07.839045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    dataset_text_field=\"text\",\n",
    "    max_length=1024,\n",
    "    packing=True,                    # å¯ç”¨ packingï¼Ÿ\n",
    "    #assistant_only_loss=True,        # åªåœ¨ assistant çš„å›å¤ä¸Šè®¡ç®—æŸå¤±    ä¼¼ä¹qwen3ä¸å…¼å®¹\n",
    "\n",
    "\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    output_dir=\"./results_8bit_new\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    save_steps=500,\n",
    "    logging_steps=1,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    bf16=True if compute_dtype == torch.bfloat16 else False,\n",
    "    fp16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=formatted_dataset,\n",
    "    peft_config=lora_config,\n",
    ")\n"
   ],
   "id": "6521b3feb5499792",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding-free training is enabled, but the attention implementation is not set to 'flash_attention_2'. Padding-free training flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation='flash_attention_2'` in the model configuration, or verify that your attention mechanism can handle flattened sequences.\n",
      "You are using packing, but the attention implementation is not set to 'flash_attention_2' or 'kernels-community/vllm-flash-attn3'. Packing flattens batches into a single sequence, and Flash Attention is the only known attention mechanisms that reliably support this. Using other implementations may lead to cross-contamination between batches. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation='flash_attention_2'` or `attn_implementation='kernels-community/vllm-flash-attn3'` in the model configuration.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T14:38:14.712781Z",
     "start_time": "2025-09-08T14:35:09.337925Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "8d298b2e86b59945",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
      "D:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "D:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13/126 02:42 < 27:51, 0.07 it/s, Epoch 0.29/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.846900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2328\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2326\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2327\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2328\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2329\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2330\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2331\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2332\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2333\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2672\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2665\u001B[39m context = (\n\u001B[32m   2666\u001B[39m     functools.partial(\u001B[38;5;28mself\u001B[39m.accelerator.no_sync, model=model)\n\u001B[32m   2667\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m i != \u001B[38;5;28mlen\u001B[39m(batch_samples) - \u001B[32m1\u001B[39m\n\u001B[32m   2668\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001B[32m   2669\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m contextlib.nullcontext\n\u001B[32m   2670\u001B[39m )\n\u001B[32m   2671\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[32m-> \u001B[39m\u001B[32m2672\u001B[39m     tr_loss_step = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2674\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2675\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   2676\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[32m   2677\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch.isinf(tr_loss_step))\n\u001B[32m   2678\u001B[39m ):\n\u001B[32m   2679\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   2680\u001B[39m     tr_loss = tr_loss + tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:1112\u001B[39m, in \u001B[36mSFTTrainer.training_step\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1110\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtraining_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m   1111\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.maybe_activation_offload_context:\n\u001B[32m-> \u001B[39m\u001B[32m1112\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4060\u001B[39m, in \u001B[36mTrainer.training_step\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m   4057\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001B[32m   4058\u001B[39m         kwargs[\u001B[33m\"\u001B[39m\u001B[33mscale_wrt_gas\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4060\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maccelerator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4062\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss.detach()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\accelerate\\accelerator.py:2734\u001B[39m, in \u001B[36mAccelerator.backward\u001B[39m\u001B[34m(self, loss, **kwargs)\u001B[39m\n\u001B[32m   2732\u001B[39m     \u001B[38;5;28mself\u001B[39m.lomo_backward(loss, learning_rate)\n\u001B[32m   2733\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2734\u001B[39m     \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\torch\\_tensor.py:647\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    637\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    638\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    639\u001B[39m         Tensor.backward,\n\u001B[32m    640\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    645\u001B[39m         inputs=inputs,\n\u001B[32m    646\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m647\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    648\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\TTP Project\\TTP\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    827\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m829\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    830\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    831\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    833\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.save_model(lora_adapter_path)",
   "id": "8872b8f8ba4fbd39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# é‡Šæ”¾ GPU æ˜¾å­˜\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 1. ä»¥ 16-bit ç²¾åº¦é‡æ–°åŠ è½½åŸºç¡€æ¨¡å‹\n",
    "print(f\"\\næ­£åœ¨ä»¥ {compute_dtype} ç²¾åº¦é‡æ–°åŠ è½½åŸºç¡€æ¨¡å‹...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=compute_dtype,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# 2. åŠ è½½ LoRA é€‚é…å™¨\n",
    "print(f\"æ­£åœ¨ä» '{lora_adapter_path}' åŠ è½½ LoRA é€‚é…å™¨...\")\n",
    "model_with_lora = PeftModel.from_pretrained(base_model, lora_adapter_path)\n",
    "\n",
    "# 3. åˆå¹¶æƒé‡\n",
    "print(\"æ­£åœ¨åˆå¹¶ LoRA æƒé‡...\")\n",
    "merged_model = model_with_lora.merge_and_unload()\n",
    "print(\"æƒé‡åˆå¹¶å®Œæˆã€‚\")\n",
    "\n",
    "# 4. ä¿å­˜å®Œæ•´æ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "print(f\"æ­£åœ¨å°†åˆå¹¶åçš„å®Œæ•´æ¨¡å‹ä¿å­˜åˆ° '{merged_model_path}'...\")\n",
    "merged_model.save_pretrained(merged_model_path)\n",
    "tokenizer.save_pretrained(merged_model_path)\n",
    "\n",
    "print(\"\\nğŸ‰ æ­å–œï¼å®Œæ•´çš„å¾®è°ƒåæ¨¡å‹å·²æˆåŠŸä¿å­˜ï¼\")\n",
    "print(f\"æ‚¨ç°åœ¨å¯ä»¥åœ¨ '{merged_model_path}' ç›®å½•ä¸‹æ‰¾åˆ°ä¸€ä¸ªå¯ä»¥ç›´æ¥ä½¿ç”¨çš„æ¨¡å‹ã€‚\")"
   ],
   "id": "43f94cb118654010"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
